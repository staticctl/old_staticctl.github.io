# CUDA执行模型概述

**Abstract:** 本文介绍CUDA执行模型，只比硬件高一层的抽象
**Keywords:** CUDA SM，SIMT，SIMD，Fermi，Kepler

参考：https://github.com/Tony-Tan/CUDA_Freshman

这一篇开始我们开始接近CUDA最核心的部分，就是有关硬件，和程序的执行模型，用CUDA的目的其实说白了就是为计算速度快，所以压榨性能，提高效率其实就是CUDA学习的最终目的，没人学CUDA为了去显示Hello world。
前面几篇我们学了编写，启动核函数，计时，统计时间，然后学习了线程，内存模型，线程内存部分我们会在后面用几章的篇幅进行大书特书，而本章，我们介绍最底层最优理论指导意义的知识。
什么时候我们沿着硬件设计的思路设计程序，我们就会得到百战百胜；什么时候我们背离了硬件设计的思路去设计程序，我们就会得不到好结果。

### 概述

CUDA执行模型揭示了GPU并行架构的抽象视图，再设计硬件的时候，其功能和特性都已经被设计好了，然后去开发硬件，如果这个过程模型特性或功能与硬件设计有冲突，双方就会进行商讨妥协，知道最后产品定型量产，功能和特性算是全部定型，而这些功能和特性就是变成模型的设计基础，而编程模型又直接反应了硬件设计，从而反映了设备的硬件特性。
比如最直观的一个就是内存，线程的层次结构帮助我们控制大规模并行，这个特性就是硬件设计最初设计好，然后集成电路工程师拿去设计，定型后程序员开发驱动，然后在上层可以直接使用这种执行模型来控制硬件。
所以了解CUDA的执行模型，可以帮助我们优化指令吞吐量，和内存使用来获得极限速度。

### GPU架构概述

 GPU架构是围绕一个流式多处理器（SM）的扩展阵列搭建的。通过复制这种结构来实现GPU的硬件并行。

![img](../image/CUDA执行模型概述/fermi_sm.png)

上图包括关键组件：

- CUDA核心
- 共享内存/一级缓存
- 寄存器文件
- 加载/存储单元
- 特殊功能单元
- 线程束调度器

